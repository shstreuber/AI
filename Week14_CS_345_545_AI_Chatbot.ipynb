{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOnj8YyowpEIBbZnZsWNMY/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shstreuber/AI/blob/main/Week14_CS_345_545_AI_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**0. What Is A Chatbot?**\n",
        "\n",
        "AI Chatbots are applications that businesses and other organizations use to automate conversations between AI and humans. These conversations can occur through text (as with Copilot) or speech (as with Alexa, for example). Chatbots must comprehend and imitate human conversation when engaging with users.\n",
        "\n",
        "In order to process a large amount of natural language data, an AI uses NLP or Natural Language Processing. NLP tasks involve breaking down human text and audio signals from voice data in ways that computers can analyze and convert into comprehensible data. Some of the tasks in NLP data ingestion include:\n",
        "\n",
        "1. **Speech Recognition,** which involves converting speech into text using a subprocess called speech tagging, which allows a computer to break down speech and add context, accents, or other speech attributes.\n",
        "2. **Word Sense Disambiguation,** which selects the most appropriate meaning for a word based on its context. For instance, it helps determine whether a word functions as a verb or a pronoun.\n",
        "3. **Named Entity Recognition (NER),** Nwhic identifies words and phrases as specific entities, such as recognizing â€œDavâ€ as a personâ€™s name or â€œAmericaâ€ as thase name of a country.\n",
        "4. **Sentiment Analysis,** which focuses on extracting nuances and hidden emotions, like attitude, sarcasm, fear, or joy, from human speech.\n",
        "\n",
        "There are essentially two types of chatbots:\n",
        "1. **Rule-Based (Scripted) Chatbots,** which operate based on predetermined scripts stored in their library. When a user inputs a query, the chatbot replies according to the predefined script within its library. One drawback of this type of chattbot is that users must structure their queries very precisely.\n",
        "2. **Self-Learning (Artificially Intelligent) Chatbots,** which rely on a combination of NLP (for analysis) and AI in order to respond to nuanced questions and learn from each interaction to provide improved responses in the future.\n",
        "\n",
        "And then a combination of the two."
      ],
      "metadata": {
        "id": "05pp5gH17vtE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Basic Text Input Chatbot**\n",
        "\n",
        "Read [this article on Analytics Vidhya](https://www.analyticsvidhya.com/blog/2021/10/complete-guide-to-build-your-ai-chatbot-with-nlp-in-python/). Here, the author is building a speech-to-text chatbot natively on Microsoft Windows. To get the code from this post working in Google Colab, we have to make some adjustments since there's an issue with building the PyAudio wheel in Google Colab. That is because, unfortunately, Google Colab does not support building packages that require compiling C extensions, such as PyAudio. That works only in MS Windows. I learned that the hard way.\n",
        "\n",
        "To rewrite the code so that it runs in Google Colab without requiring PyAudio or needing to connect to your local microphone, we will replace the speech-to-text functionality with text input.\n",
        "\n",
        "**NOTE:** The code below  generates a right-padding warning (which sent me down a fruitless hours-long debugging path) but works as intended by carrying on a conversation."
      ],
      "metadata": {
        "id": "eQba7ARyQJGl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we import all the libraries we need"
      ],
      "metadata": {
        "id": "vAxzvVMuX5ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import datetime\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch"
      ],
      "metadata": {
        "id": "KL0CEK5mXl-r"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure that all libraries are compatible with Python 3.10, we are going to do a few checks now. We need transformers >= 4.12 and torch >= 1.10 (or higher)"
      ],
      "metadata": {
        "id": "FKf7yEU4H-hC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip show transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9JpGYiuIHai",
        "outputId": "8d3a5a7e-c3b9-4853-e975-899e49184e51"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: transformers\n",
            "Version: 4.51.3\n",
            "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
            "Home-page: https://github.com/huggingface/transformers\n",
            "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
            "Author-email: transformers@huggingface.co\n",
            "License: Apache 2.0 License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
            "Required-by: peft, sentence-transformers\n",
            "---\n",
            "Name: torch\n",
            "Version: 2.6.0+cu124\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3-Clause\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-cusparselt-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n",
            "Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we build a ChatBot class to provide functionality for initializing the chatbot, getting user input, responding to user input, checking for specific commands, and providing the current time.:\n",
        "\n",
        "1. Initialization (__init__ method):\n",
        "When you create a new instance of the ChatBot class, it initializes with a specified name. This name is printed to indicate that the chatbot is starting up.\n",
        "2. Getting User Input (get_text_input method):\n",
        "This method prompts the user to enter text input, and it returns the input provided by the user.\n",
        "3. Text Output (text_to_speech method):\n",
        "This method takes a text input and prints it to the console, simulating the chatbot's response.\n",
        "4. Wake-Up Check (wake_up method):\n",
        "This method checks if the chatbot's name (converted to lowercase) is mentioned in the text input. If it is, it returns True; otherwise, it returns False.\n",
        "5. Time Action (action_time method):\n",
        "This method retrieves the current time and returns it in the format \"HH:MM\".\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fsAZ3hCzX88L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ChatBot class\n",
        "class ChatBot:\n",
        "    def __init__(self, name=\"ChatBot\"):\n",
        "        print(\"----- Starting up\", name, \"-----\")\n",
        "        self.name = name.lower()\n",
        "\n",
        "    def get_text_input(self):\n",
        "        return input(\"You --> \")\n",
        "\n",
        "    @staticmethod\n",
        "    def text_to_speech(text: str):\n",
        "        print(\"ChatBot -->\", text)\n",
        "\n",
        "    def wake_up(self, text: str) -> bool:\n",
        "        return self.name in text.lower()\n",
        "\n",
        "    @staticmethod\n",
        "    def action_time() -> str:\n",
        "        return datetime.datetime.now().strftime('%H:%M')"
      ],
      "metadata": {
        "id": "4_FZGcytXtoy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we build a response generator function.\n",
        "\n",
        "The **`generate_response`** function processes user input to generate a contextually relevant response using the `DialoGPT` model. It first tokenizes the user's input and appends it to the conversation history (if any). The function then generates a response by passing the combined input and history to the model, using parameters like `top_k`, `top_p`, and `temperature` to control the randomness and diversity of the response. After generating the output tokens, the function decodes them into human-readable text and returns both the response and the updated conversation history, ensuring that future responses maintain the context of the entire dialogue. This allows the chatbot to provide coherent, conversational replies."
      ],
      "metadata": {
        "id": "Q7qyE2zDKcQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Response generator function\n",
        "def generate_response(user_input, chat_history_ids, tokenizer, model, device):\n",
        "    new_input_ids = tokenizer.encode(user_input + tokenizer.eos_token, return_tensors='pt').to(device)\n",
        "    bot_input_ids = torch.cat([chat_history_ids, new_input_ids], dim=-1) if chat_history_ids is not None else new_input_ids\n",
        "\n",
        "    chat_history_ids = model.generate(\n",
        "        bot_input_ids,\n",
        "        max_length=1000,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.75,\n",
        "    )\n",
        "\n",
        "    response = tokenizer.decode(chat_history_ids[:, bot_input_ids.shape[-1]:][0], skip_special_tokens=True)\n",
        "    return response, chat_history_ids"
      ],
      "metadata": {
        "id": "IcBsxjzxKgId"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the chatbot, we need to initialize the chatbot, load the necessary components (tokenizer and conversational pipeline), greet the user, handle user input, process commands, engage in conversation, and exit gracefully when prompted.\n",
        "\n",
        "**NOTE**: When starting up the chatbot, you will see a `HF_Token` Warning. This warning is telling you that you donâ€™t have the authentication token (`HF_TOKEN`) set up in Colabâ€™s secret storage. Hugging Face allows you to work with models without authentication, but itâ€™s recommended for easier access and use of the Hugging Face Hub. Authentication may be required in certain situations (e.g., for private models or for rate-limited API access). In our case, you don't need to authenticate to use public models like DialoGPT. This warning can be safely ignored unless you're working with private models or want the benefits of authentication.\n",
        "\n",
        "Here is how all of this magic happens:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y07P05K-Ycnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main runner\n",
        "if __name__ == \"__main__\":\n",
        "    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    chatbot = ChatBot(name=\"ChatBot\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\").to(device)\n",
        "\n",
        "    chatbot.text_to_speech(\"Hello, I am ChatBot. How can I assist you today?\")\n",
        "\n",
        "    chat_history_ids = None\n",
        "    active = True\n",
        "\n",
        "    while active:\n",
        "        user_input = chatbot.get_text_input().strip()\n",
        "\n",
        "        if chatbot.wake_up(user_input):\n",
        "            response = \"Hello, I am ChatBot. How can I assist you today?\"\n",
        "\n",
        "        elif \"time\" in user_input.lower():\n",
        "            response = chatbot.action_time()\n",
        "\n",
        "        elif any(word in user_input.lower() for word in [\"thank\", \"thanks\"]):\n",
        "            response = np.random.choice([\n",
        "                \"You're welcome!\", \"Anytime!\", \"No problem!\", \"Cool!\",\n",
        "                \"I'm here if you need me!\", \"Mention not\"\n",
        "            ])\n",
        "\n",
        "        elif any(word in user_input.lower() for word in [\"exit\", \"close\", \"bye\"]):\n",
        "            response = np.random.choice([\n",
        "                \"Tata\", \"Have a good day\", \"Bye\", \"Goodbye\", \"Hope to meet soon\", \"Peace out!\"\n",
        "            ])\n",
        "            active = False\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                response, chat_history_ids = generate_response(user_input, chat_history_ids, tokenizer, model, device)\n",
        "            except Exception as e:\n",
        "                response = f\"Oops! Something went wrong: {e}\"\n",
        "\n",
        "        chatbot.text_to_speech(response)\n",
        "\n",
        "    print(\"----- Closing down ChatBot -----\")"
      ],
      "metadata": {
        "id": "P6qqLHgnXysc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec40871a-eac9-4002-90ac-f28f0f1a79e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Starting up ChatBot -----\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatBot --> Hello, I am ChatBot. How can I assist you today?\n",
            "You --> Tell me the time\n",
            "ChatBot --> 03:10\n",
            "You --> Super\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatBot --> Oh god, I'm so sorry.\n",
            "You --> What are you sorry about?\n",
            "ChatBot --> You're sorry\n",
            "You --> No, you are sorry\n",
            "ChatBot --> I'm sorry.\n",
            "You --> Yes. Why?\n",
            "ChatBot --> I think I'm sorry.\n",
            "You --> Why do you think you are sorry?\n",
            "ChatBot --> I think you're sorry\n",
            "You --> Thank you. good bye\n",
            "ChatBot --> Mention not\n",
            "You --> exit\n",
            "ChatBot --> Bye\n",
            "----- Closing down ChatBot -----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Chatbot Using OpenAI**\n",
        "Yes, GPT!\n",
        "\n",
        "Try the solution in the video out below. I've started you off below with installing the appropriate version of openai"
      ],
      "metadata": {
        "id": "jwqzgkkN8G3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/q5HiD5PNuck?si=ETpeM3-4NInvR_s9\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowfullscreen></iframe>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "xvKjICQSoXqk",
        "outputId": "4e8c326c-a1b2-48c1-c14d-fb3db12f09ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/display.py:724: UserWarning: Consider using IPython.display.IFrame instead\n",
            "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/q5HiD5PNuck?si=ETpeM3-4NInvR_s9\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\"allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install OpenAI\n",
        "!pip install openai==0.28 # You will need this version of openai to make the code in the video work."
      ],
      "metadata": {
        "id": "Q8HnmPW28NEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "-PLLSIec8jpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now get a project API key from https://platform.openai.com/api-keys and add it below"
      ],
      "metadata": {
        "id": "Hb2Rk9GA89zP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = 'your API key here'"
      ],
      "metadata": {
        "id": "ON-QK0868uFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Type here the code from the video and try it out"
      ],
      "metadata": {
        "id": "ynTtIXyBqH1U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p0yvOAYqAHFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. A More Advanced Chatbot Using Chatterbot**\n",
        "This example comes from [hubspot](https://blog.hubspot.com/website/python-ai-chat-bot). The code uses the [Chatterbot AI framework](https://chatterbot.readthedocs.io/en/stable/), a conversational dialog engine. For the Chatterbot Quickstart, check [here](https://chatterbot.readthedocs.io/en/stable/quickstart.html).\n",
        "\n",
        "***NOTE:*** Implementing Chatterbot on Google Colab used to require rolling back the Google Colab Python version to 3.8-full. It does not any more. A previous version of this notebook contains that code."
      ],
      "metadata": {
        "id": "9MM8xa2GRMCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Installing required libraries--this takes a looooooooong time!\n",
        "\n",
        "#!pip install pyyaml==5.1.1 # should not be necessary\n",
        "!pip install chatterbot\n",
        "!python -m chatterbot --version\n",
        "\n",
        "# To install the chatterbot corpus, we should be able to use the simple pip command, but need to instead clone the git repo\n",
        "# !pip install chatterbot-corpus ##--this should work, but doesn't\n",
        "!git clone https://github.com/gunthercox/chatterbot-corpus.git"
      ],
      "metadata": {
        "id": "LBwr2-aJ1jXv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to import the libraries we need."
      ],
      "metadata": {
        "id": "aoy45ZJ6BSMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Importing required libraries\n",
        "import os\n",
        "\n",
        "# Import chatterbot\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "\n",
        "# Check if the corpus is installed correctly, including the English library\n",
        "os.listdir('chatterbot-corpus/chatterbot_corpus/data')"
      ],
      "metadata": {
        "id": "qoLrj8fp1yef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc3cb9e-4931-4846-f8f5-05b3c50f4e2d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['persian',\n",
              " 'tamil',\n",
              " 'japanese',\n",
              " 'indonesian',\n",
              " 'chinese',\n",
              " 'turkish',\n",
              " 'thai',\n",
              " 'swedish',\n",
              " 'french',\n",
              " 'hebrew',\n",
              " 'hindi',\n",
              " 'italian',\n",
              " 'traditionalchinese',\n",
              " 'telugu',\n",
              " 'marathi',\n",
              " 'korean',\n",
              " 'oriya',\n",
              " 'spanish',\n",
              " 'english',\n",
              " 'german',\n",
              " 'russian',\n",
              " 'dutch',\n",
              " 'portuguese',\n",
              " 'bengali']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 2.1 What is in the English library?\n",
        "!ls -R chatterbot-corpus/chatterbot_corpus/data/english/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtuyiiBdO9G6",
        "outputId": "4d600946-e69d-47a3-deb9-cb2ca22684a0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chatterbot-corpus/chatterbot_corpus/data/english/:\n",
            "ai.yml\t\t   emotion.yml\t  health.yml\t  money.yml\t  science.yml\n",
            "botprofile.yml\t   food.yml\t  history.yml\t  movies.yml\t  sports.yml\n",
            "computers.yml\t   gossip.yml\t  humor.yml\t  politics.yml\t  trivia.yml\n",
            "conversations.yml  greetings.yml  literature.yml  psychology.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Initializing the ChatBot\n",
        "chatbot = ChatBot(\n",
        "    'ExampleBot',\n",
        "    storage_adapter='chatterbot.storage.SQLStorageAdapter',\n",
        "    database_uri='sqlite:///database.db',  # Use SQLite database to store conversation history\n",
        "    logic_adapters=[\n",
        "        'chatterbot.logic.BestMatch',\n",
        "        'chatterbot.logic.MathematicalEvaluation',  # This allows the bot to handle math-related questions\n",
        "        'chatterbot.logic.TimeLogicAdapter',  # The bot will be able to tell time\n",
        "    ],\n",
        "    preprocessors=['chatterbot.preprocessors.clean_whitespace'],  # Clean the user input\n",
        ")"
      ],
      "metadata": {
        "id": "mLQPSOwu1872"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Creating a new instance of a ChatterBotCorpusTrainer and training the bot with the English corpus\n",
        "trainer = ChatterBotCorpusTrainer(chatbot)\n",
        "trainer.train('/content/chatterbot-corpus/chatterbot_corpus/data/english')"
      ],
      "metadata": {
        "id": "ZlSIoti4NvVg"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. Function to get a response from the bot\n",
        "def get_response(user_input):\n",
        "    return chatbot.get_response(user_input)"
      ],
      "metadata": {
        "id": "STmry5Zw2FH6"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now, we are ready to test our chatbot!"
      ],
      "metadata": {
        "id": "KyrAHzK3RfLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 6. Test the chatbot\n",
        "print(\"Type 'exit' to end the conversation.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Goodbye!\")\n",
        "        break\n",
        "    response = get_response(user_input)\n",
        "    print(f\"Bot: {response}\")"
      ],
      "metadata": {
        "id": "6CaTzqZV2Fez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3a0863-a715-438a-a728-1bbbf69505b9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 'exit' to end the conversation.\n",
            "You: exit\n",
            "Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BUT** that is boring! How about actually training the chatbot with our own data? Here is how we will make that work:\n",
        "\n",
        "* `ListTrainer`: This trainer allows you to train the chatbot using a list of conversation pairs (like a small dialogue).\n",
        "\n",
        "* Training: The `trainer.train([...])` command feeds the conversation into the chatbot's training process.\n",
        "\n",
        "* Testing: After training, you can test it by getting a response from the bot using `chatbot.get_response()`.\n",
        "\n",
        "This will allow the chatbot to respond based on the provided conversation, and you can expand it further with more phrases or different topics."
      ],
      "metadata": {
        "id": "Gra3NK1sRqPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Training with Custom Data\n",
        "from chatterbot.trainers import ListTrainer\n",
        "trainer = ListTrainer(chatbot)\n",
        "trainer.train([\n",
        "\"How are you?\",\n",
        "\"I am good.\",\n",
        "\"That is good to hear.\",\n",
        "\"Thank you\",\n",
        "\"You're welcome.\"\n",
        "])"
      ],
      "metadata": {
        "id": "6ufnXLHU2UwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c0218b-b334-4044-90dd-952b788cc9c3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "List Trainer: 5it [00:00, 188.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing the Custom Data\n",
        "response = chatbot.get_response(\"How are you?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuhXeaWNSJ0I",
        "outputId": "bf0df5bc-1c4c-48c9-c9f3-3265a7577c40"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am doing well.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Want something even more fun? Then, you'll have to increase the size of the training library:"
      ],
      "metadata": {
        "id": "D8XJavC_S9q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the chatbot\n",
        "chatbot = ChatBot('FunBot')\n",
        "\n",
        "# Set up the trainer\n",
        "trainer = ListTrainer(chatbot)\n",
        "\n",
        "# Train the chatbot with a more interesting and varied conversation\n",
        "trainer.train([\n",
        "    \"How are you?\",\n",
        "    \"I'm doing fantastic, thanks for asking!\",\n",
        "    \"Whatâ€™s up?\",\n",
        "    \"Not much, just hanging out here with you!\",\n",
        "    \"Tell me a joke.\",\n",
        "    \"Why don't skeletons fight each other? They don't have the guts!\",\n",
        "    \"What's your favorite color?\",\n",
        "    \"I like blue, but I'm open to all colors!\",\n",
        "    \"Do you like music?\",\n",
        "    \"Absolutely! I love all kinds of music, especially upbeat tunes. How about you?\",\n",
        "    \"Whatâ€™s your favorite food?\",\n",
        "    \"I don't eat, but I think pizza sounds like a great choice!\",\n",
        "    \"Where are you from?\",\n",
        "    \"Iâ€™m from the digital world, always connected and learning.\",\n",
        "    \"Can you help me with math?\",\n",
        "    \"Sure! What's the problem? I can add, subtract, multiply... well, you get the idea!\",\n",
        "    \"What's the weather like?\",\n",
        "    \"I canâ€™t check the weather, but Iâ€™d imagine itâ€™s perfect wherever you are!\",\n",
        "    \"Thank you\",\n",
        "    \"You're very welcome! If you need more help, just let me know.\",\n",
        "    \"Tell me something interesting.\",\n",
        "    \"Did you know that honey never spoils? Archaeologists have found pots of honey in ancient tombs, and itâ€™s still good to eat!\",\n",
        "    \"Goodbye\",\n",
        "    \"Goodbye! Come back soon, Iâ€™ll be here!\"\n",
        "])"
      ],
      "metadata": {
        "id": "gyOgxYWbTDZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now you can test it with a number of questions:"
      ],
      "metadata": {
        "id": "T4beBrmdTKpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the chatbot with a variety of inputs\n",
        "print(chatbot.get_response(\"How are you?\"))\n",
        "print(chatbot.get_response(\"Tell me a joke\"))\n",
        "print(chatbot.get_response(\"Can you help me with math?\"))\n",
        "print(chatbot.get_response(\"What's the weather like?\"))\n",
        "print(chatbot.get_response(\"Goodbye\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rzLc5m2TN1B",
        "outputId": "9003d70f-df8a-4b59-e014-08ce850b2897"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm doing fantastic, thanks for asking!\n",
            "Why don't skeletons fight each other? They don't have the guts!\n",
            "Sure! What's the problem? I can add, subtract, multiply... well, you get the idea!\n",
            "I canâ€™t check the weather, but Iâ€™d imagine itâ€™s perfect wherever you are!\n",
            "Goodbye! Come back soon, Iâ€™ll be here!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Integrating Your Chatbot into a web page**\n",
        "\n",
        "In order to run your chatbot from a web page, you need a number of components:\n",
        "\n",
        "1. **A webserver:** The Flask code below sets up a basic web server that integrates a chatbot using the ChatterBot library. It defines two routes: the root route (`\"/\"`) renders an HTML page (`index.html`) that serves as the chat interface, and the `\"/get\"` route receives user input via a GET request and returns the chatbot's response. When a user types a message on the webpage, JavaScript sends it to the `/get` endpoint, where the chatbot processes the message and responds. The response is then displayed on the webpage, enabling real-time interaction between the user and the bot through a simple browser interface.\n",
        "\n",
        "2. **A page:** You need a simple front-end interface for your chatbot. Below, we create a folder named templates in the same directory as your Flask app, and inside it, we create a file named index.html."
      ],
      "metadata": {
        "id": "7fkRFoooTi8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Cleaning up Chatterbot for Google Colab**"
      ],
      "metadata": {
        "id": "BGMaJzlYXxwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Starting with a clean install of a Chatterbot version that This version avoids strict PyYAML version pinning and works fine in Colab.\n",
        "\n",
        "!pip uninstall chatterbot -y\n",
        "!pip install git+https://github.com/gunthercox/ChatterBot.git@master"
      ],
      "metadata": {
        "id": "-DeM9tuGXMbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Testing the install\n",
        "\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "\n",
        "bot = ChatBot(\"Test Bot\")\n",
        "trainer = ChatterBotCorpusTrainer(bot)\n",
        "trainer.train(\"chatterbot.corpus.english\")\n",
        "\n",
        "response = bot.get_response(\"Hello, how are you?\")\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5efEp6hXiZI",
        "outputId": "5e36bfaf-4589-4e50-f73b-a63eeb5726d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ChatterBot Corpus Trainer: 19it [00:04,  4.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm doing fantastic, thanks for asking!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIWj-qNAac3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Set Up a Simple Flask Web Interface with `flask-pyngrok`**\n",
        "\n",
        "In order to set up a Flask webserver, you will need an ngrok authentication token. This requires the following steps:\n",
        "\n",
        "* **Step 1:** Install pyngrok\n",
        "* **Step 2:** Create an ngrok account (if you don't have one)\n",
        "Go to: https://dashboard.ngrok.com/signup\n",
        "* **Step 3:** Get your authtoken.\n",
        "\n",
        "  After logging in, visit:\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "  Copy your token â€” it looks like this:\n",
        "`1h2g3exampleAuthtoken4u5x6y`\n",
        "\n",
        "* **Step 4:** Install the authtoken in Colab and test connectivity (see below)"
      ],
      "metadata": {
        "id": "l1MlroqMX_c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhsYPSWyZN3C",
        "outputId": "aeeefbff-0871-4aac-8ede-47d114f8da9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.4-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.4-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace with your actual token\n",
        "ngrok.set_auth_token(\"YOUR_AUTHTOKEN_HERE\") # replace with your auth token; keep the \"\"\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸ”¥ Public URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF2lF5xabqYy",
        "outputId": "a3fc9a81-c7cc-4fbf-a414-e18b18cc4309"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ Public URL: NgrokTunnel: \"https://0062-34-169-117-127.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Create the Chatbot Instance**"
      ],
      "metadata": {
        "id": "cKl-N-tOcycy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template_string, request, jsonify\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Create a Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Create a chatbot instance\n",
        "chatbot = ChatBot(\"ChatterBot\")\n",
        "trainer = ChatterBotCorpusTrainer(chatbot)\n",
        "trainer.train(\"chatterbot.corpus.english\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L6vPJg0UUtx",
        "outputId": "913d3b0f-b058-401d-ab9e-b1d1f0d85cb8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ChatterBot Corpus Trainer: 19it [00:05,  3.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Step 4: Build the Web Front End**"
      ],
      "metadata": {
        "id": "NZIjyJtfdAxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HTML + JS frontend\n",
        "html_template = \"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Chat with Bot</title>\n",
        "    <style>\n",
        "        body { font-family: Arial; background: #f4f4f4; padding: 30px; }\n",
        "        #chatbox { background: white; border: 1px solid #ccc; padding: 15px; height: 400px; overflow-y: scroll; }\n",
        "        .msg { margin: 10px 0; }\n",
        "        .user { color: blue; }\n",
        "        .bot { color: green; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Chat with ChatterBot ðŸ¤–</h2>\n",
        "    <div id=\"chatbox\"></div>\n",
        "    <input type=\"text\" id=\"input\" placeholder=\"Say something...\" autofocus>\n",
        "    <button onclick=\"send()\">Send</button>\n",
        "\n",
        "    <script>\n",
        "        async function send() {\n",
        "            let input = document.getElementById(\"input\");\n",
        "            let text = input.value;\n",
        "            input.value = \"\";\n",
        "\n",
        "            let chatbox = document.getElementById(\"chatbox\");\n",
        "            chatbox.innerHTML += `<div class='msg user'>You: ${text}</div>`;\n",
        "\n",
        "            let res = await fetch(\"/get\", {\n",
        "                method: \"POST\",\n",
        "                headers: { \"Content-Type\": \"application/json\" },\n",
        "                body: JSON.stringify({ message: text })\n",
        "            });\n",
        "\n",
        "            let data = await res.json();\n",
        "            chatbox.innerHTML += `<div class='msg bot'>Bot: ${data.reply}</div>`;\n",
        "            chatbox.scrollTop = chatbox.scrollHeight;\n",
        "        }\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Routes\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return render_template_string(html_template)\n",
        "\n",
        "@app.route(\"/get\", methods=[\"POST\"])\n",
        "def get_bot_response():\n",
        "    user_text = request.json[\"message\"]\n",
        "    response = str(chatbot.get_response(user_text))\n",
        "    return jsonify(reply=response)\n",
        "\n",
        "# Expose the app\n",
        "ngrok.set_auth_token(\"YOUR_AUTHTOKEN_HERE\")  # Replace with your real token; keep the \"\"\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸ”¥ Chatbot is live at: {public_url}\")\n",
        "\n",
        "app.run(port=5000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCWdzLlsdFz4",
        "outputId": "e3b39b2c-0e35-4adf-a676-776addf636d4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¥ Chatbot is live at: NgrokTunnel: \"https://6d20-34-169-117-127.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2025 04:30:19] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Apr/2025 04:30:19] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What this does**:\n",
        "\n",
        "* Starts a chatbot (trained on chatterbot.corpus.english)\n",
        "\n",
        "* Serves a lightweight chat UI via Flask\n",
        "\n",
        "* Uses JavaScript to send and receive messages without reloading\n",
        "\n",
        "* Ngrok exposes it publicly so you can share the link or test on your phone\n",
        "\n",
        "In the end, ysou should see a line saying\n",
        "\n",
        "`Chatbot is live at: NgrokTunnel: \"https://6d20-34-169-117-127.ngrok-free.app\"`\n",
        "\n",
        "or a similar link. Click on the link, and you should see your chatbot webpage. It will look like this:\n",
        "\n",
        "<img src= \"https://raw.githubusercontent.com/shstreuber/Data-Mining/refs/heads/master/images/Week14_Chatterbot.png\">\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-TL8lZcydrRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Challenges and Solutions in Building Python AI Chatbots**\n",
        "\n",
        "1. **Challenge 1: Understanding User Intent**\n",
        "   \n",
        "   **Problem:** One of the biggest challenges in chatbot development is accurately understanding user intent. As language can be ambiguous and context-dependent, deciphering what a user truly means can be complex.\n",
        "\n",
        "   **Solution:** Utilize NLP techniques like Named Entity Recognition (NER) and Intent Classification to interpret user input. Leverage machine learning models trained on large datasets to better recognize and respond to varied user queries.\n",
        "\n",
        "2. **Challenge 2: Handling Conversational Context**\n",
        "   **Problem:*** Maintaining the context of a conversation is crucial for delivering coherent responses. Without this, the chatbot might not understand references to previous messages, leading to a disjointed conversation.\n",
        "\n",
        "   **Solution:** Implement context management in your chatbot using techniques like dialogue management and session tracking. Libraries like Rasa provide tools for managing conversational context.\n",
        "\n",
        "3. **Challenge 3: Dealing with Unfamiliar Queries**\n",
        "   **Problem:** Chatbots, especially rule-based ones, might stumble upon unfamiliar or out-of-scope queries, which can disrupt the user experience.\n",
        "\n",
        "   **Solution:** Train your chatbot to handle unfamiliar queries gracefully. This could involve directing users to human support or suggesting alternate queries. Additionally, incorporate regular updates and training to your chatbot based on new and trending queries.\n",
        "\n",
        "4. **Challenge 4: Lack of Personalization**\n",
        "   **Problem:** Generic responses can make interactions with a chatbot feel mechanical and impersonal, diminishing user engagement.\n",
        "\n",
        "   **Solution:** Implement personalization in your chatbot. This could range from using the user's name to tailoring responses based on user preferences and past interactions.\n",
        "\n",
        "5. **Challenge 5: Scaling and Deployment**\n",
        "   **Problem:** As your chatbot gets more complex and traffic increases, it may face issues related to performance, scalability, and deployment.\n",
        "\n",
        "   **Solution:** Plan for scalability from the get-go. Utilize scalable cloud services and robust deployment practices. Monitor performance regularly and optimize as needed.\n",
        "\n",
        "Remember, overcoming these challenges is part of the journey of developing a successful chatbot. Each challenge presents an opportunity to learn and improve, ultimately leading to a more sophisticated and engaging chatbot."
      ],
      "metadata": {
        "id": "NFeLDq_d2vG8"
      }
    }
  ]
}